{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e71b3c7-4f61-4f58-9348-2a7e90b68a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd           # Handle tabular survey data (DataFrame-based pipeline)\n",
    "import numpy as np           # Load trained machine learning models from disk\n",
    "\n",
    "from joblib import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f28e8741-4f42-4131-9820-e32d6d54a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ai_governance_vision(\n",
    "    df,\n",
    "    # DataFrame containing the survey responses\n",
    "\n",
    "    items=(\"VUTAI1\", \"VUTAI2\", \"VUTAI3\"),\n",
    "    # Survey items used to measure AI governance vision\n",
    "\n",
    "    method=\"mean\",\n",
    "    # Method used to compute the score (mean of the items),\n",
    "    # kept for conceptual clarity even if only one method is currently used\n",
    "\n",
    "    score_col=\"AI_Governance_Vision\",\n",
    "    # Name of the column that will store the raw AI governance vision score\n",
    "\n",
    "    pct_col=\"AI_Governance_Vision_Pct\",\n",
    "    # Name of the column that will store the percentage score\n",
    "\n",
    "    scale_min=1,\n",
    "    # Minimum value of the Likert scale used in the questionnaire\n",
    "\n",
    "    scale_max=4\n",
    "    # Maximum value of the Likert scale used in the questionnaire\n",
    "):\n",
    "    # -------------------------------------------------\n",
    "    # Step 1: Compute the raw AI governance vision score\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    # Compute the row-wise mean of the VUTAI items\n",
    "    # Each row corresponds to one institution or respondent\n",
    "    score = df[list(items)].mean(axis=1)\n",
    "\n",
    "    # Store the raw score in the DataFrame\n",
    "    df[score_col] = score\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Step 2: Convert the raw score into a percentage\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    # Transform the raw score into a 0–100 percentage\n",
    "    # This makes the result easier to interpret and compare\n",
    "    df[pct_col] = ((score - scale_min) / (scale_max - scale_min)) * 100\n",
    "\n",
    "    # Return the DataFrame with the computed scores\n",
    "    return df\n",
    "\n",
    "\n",
    "def interpret_vision_pct(pct):\n",
    "    # This function converts a percentage score\n",
    "    # into a qualitative interpretation\n",
    "\n",
    "    # If the score is below 33%, AI governance vision is low\n",
    "    if pct < 33:\n",
    "        return \"Low AI Governance Vision\"\n",
    "\n",
    "    # If the score is between 33% and 66%, vision is moderate\n",
    "    elif pct < 66:\n",
    "        return \"Moderate AI Governance Vision\"\n",
    "\n",
    "    # If the score is 66% or higher, vision is high\n",
    "    else:\n",
    "        return \"High AI Governance Vision\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af725375-39cf-4497-aa50-670140b988ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model for VUTAI1: ML_BestModel_VUTAI_VUTAI1_RidgeRegression.joblib\n",
      "Loaded best model for VUTAI2: ML_BestModel_VUTAI_VUTAI2_RandomForest.joblib\n",
      "Loaded best model for VUTAI3: ML_BestModel_VUTAI_VUTAI3_RandomForest.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator Ridge from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Feature configuration for ML-based AI governance prediction\n",
    "# ============================================================\n",
    "\n",
    "FEATURE_ORDER = [\n",
    "    \"EST1\", \"EST3\", \"EST4\",\n",
    "    \"OUAI2\", \"OUAI3\", \"OUAI4\",\n",
    "    \"PBUG1\", \"PBUG2\", \"PBUG3\", \"PBUG4\"\n",
    "]\n",
    "# Ordered list of input features used by the trained ML models.\n",
    "# IMPORTANT: The order must be exactly the same as during training,\n",
    "# otherwise, the predictions will be incorrect.\n",
    "# ============================================================\n",
    "# Required libraries for model loading and file handling\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from joblib import load\n",
    "\n",
    "# Model storage configuration\n",
    "MODEL_DIR = \"Models\"\n",
    "# Path to the directory where trained ML models are stored\n",
    "loaded_models = {}\n",
    "\n",
    "# We only care about predicting the three vision items\n",
    "VISION_TARGETS = [\"VUTAI1\", \"VUTAI2\", \"VUTAI3\"]\n",
    "\n",
    "for target in VISION_TARGETS:\n",
    "\n",
    "    # Find the saved model file for this target\n",
    "    matching_files = [\n",
    "        f for f in os.listdir(MODEL_DIR)\n",
    "        if f.startswith(f\"ML_BestModel_VUTAI_{target}_\") and f.endswith(\".joblib\")\n",
    "    ]\n",
    "\n",
    "    if len(matching_files) == 0:\n",
    "        raise FileNotFoundError(f\"No saved best model found for {target}\")\n",
    "\n",
    "    if len(matching_files) > 1:\n",
    "        raise ValueError(f\"Multiple models found for {target}: {matching_files}\")\n",
    "\n",
    "    model_file = matching_files[0]\n",
    "    model_path = os.path.join(MODEL_DIR, model_file)\n",
    "\n",
    "    # Load model\n",
    "    loaded_models[target] = {\n",
    "        \"model\": load(model_path),\n",
    "        \"features\": FEATURE_ORDER\n",
    "    }\n",
    "    \n",
    "# Confirmation message to ensure correct model loading\n",
    "    \n",
    "    print(f\"Loaded best model for {target}: {model_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57f1690c-3ac0-4de8-8a41-74a40dc19121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model for VUTAI1: ML_BestModel_VUTAI_VUTAI1_RidgeRegression.joblib\n",
      "Loaded best model for VUTAI2: ML_BestModel_VUTAI_VUTAI2_RandomForest.joblib\n",
      "Loaded best model for VUTAI3: ML_BestModel_VUTAI_VUTAI3_RandomForest.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator Ridge from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "FEATURE_ORDER = [\n",
    "    \"EST1\", \"EST3\", \"EST4\",\n",
    "    \"OUAI2\", \"OUAI3\", \"OUAI4\",\n",
    "    \"PBUG1\", \"PBUG2\", \"PBUG3\", \"PBUG4\"\n",
    "]\n",
    "\n",
    "\n",
    "import os\n",
    "from joblib import load\n",
    "\n",
    "MODEL_DIR = \"Models\"\n",
    "\n",
    "loaded_models = {}\n",
    "\n",
    "# We only care about predicting the three vision items\n",
    "VISION_TARGETS = [\"VUTAI1\", \"VUTAI2\", \"VUTAI3\"]\n",
    "\n",
    "for target in VISION_TARGETS:\n",
    "\n",
    "    # Find the saved model file for this target\n",
    "    matching_files = [\n",
    "        f for f in os.listdir(MODEL_DIR)\n",
    "        if f.startswith(f\"ML_BestModel_VUTAI_{target}_\") and f.endswith(\".joblib\")\n",
    "    ]\n",
    "\n",
    "    if len(matching_files) == 0:\n",
    "        raise FileNotFoundError(f\"No saved best model found for {target}\")\n",
    "\n",
    "    if len(matching_files) > 1:\n",
    "        raise ValueError(f\"Multiple models found for {target}: {matching_files}\")\n",
    "\n",
    "    model_file = matching_files[0]\n",
    "    model_path = os.path.join(MODEL_DIR, model_file)\n",
    "\n",
    "    # Load model\n",
    "    loaded_models[target] = {\n",
    "        \"model\": load(model_path),\n",
    "        \"features\": FEATURE_ORDER\n",
    "    }\n",
    "\n",
    "    print(f\"Loaded best model for {target}: {model_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b292afe-a258-42d8-82d5-990fc0d88294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the vision score of M5 University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d9831f2-0c72-4dd7-a8f0-fed457e4141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 13)\n",
      "['PBUG1', 'PBUG2', 'PBUG3', 'PBUG4', 'OUAI2', 'OUAI3', 'OUAI4', 'EST1', 'EST3', 'EST4', 'VUTAI1', 'VUTAI2', 'VUTAI3']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Used for numerical operations if needed later in the pipeline\n",
    "import pandas as pd  # Used to load and manipulate tabular data (DataFrame structure)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"last_data.xlsx\")\n",
    "\n",
    "# Drop empty Excel artifact columns\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "# Sanity check\n",
    "print(df.shape) \n",
    "# Print the dataset dimensions (number of rows and columns)\n",
    "print(df.columns.tolist())\n",
    "# Print the list of column names to verify correct data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46342a42-8f6c-4306-833a-2626995b6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Vision score and percentage on training data\n",
    "df = compute_ai_governance_vision(\n",
    "    df,\n",
    "    # Input DataFrame containing the survey responses\n",
    "    items=(\"VUTAI1\", \"VUTAI2\", \"VUTAI3\"),\n",
    "    \n",
    "     # Survey items used to compute the AI governance vision score\n",
    "    score_col=\"AI_Governance_Vision\",\n",
    "    \n",
    "    # Column name for the computed raw vision score\n",
    "    pct_col=\"AI_Governance_Vision_Pct\",\n",
    "      # Column name for the computed percentage score\n",
    "    \n",
    "    scale_min=1,\n",
    "     # Minimum value of the Likert scale\n",
    "    \n",
    "    scale_max=4\n",
    "     # Minimum value of the Likert scale\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e472bdc2-0b94-412c-ab1d-24b1ab883c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AI Governance Vision (mean): 3.474\n",
      "Standard deviation: 0.695\n"
     ]
    }
   ],
   "source": [
    "# Compute summary statistics for AI governance vision (raw score)\n",
    "\n",
    "overall_vision_mean = df[\"AI_Governance_Vision\"].mean()\n",
    "# Compute the average AI governance vision score across all observationsoverall_vision_std = df[\"AI_Governance_Vision\"].std()\n",
    "\n",
    "overall_vision_std = df[\"AI_Governance_Vision\"].std()\n",
    "# Compute the standard deviation of the AI governance vision score\n",
    "\n",
    "print(f\"Overall AI Governance Vision (mean): {overall_vision_mean:.3f}\")\n",
    "# Display the mean raw vision score with three decimal precision\n",
    "print(f\"Standard deviation: {overall_vision_std:.3f}\")\n",
    "# Display the standard deviation of the raw vision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8661048-b6a5-430d-a575-880a686c841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AI Governance Vision (%): 82.5%\n",
      "Standard deviation (%): 23.2%\n"
     ]
    }
   ],
   "source": [
    "# Compute summary statistics for AI governance vision (percentage score)\n",
    "\n",
    "overall_vision_pct_mean = df[\"AI_Governance_Vision_Pct\"].mean()\n",
    "# Compute the average AI governance vision percentage score\n",
    "\n",
    "overall_vision_pct_std = df[\"AI_Governance_Vision_Pct\"].std()\n",
    "# Compute the standard deviation of the AI governance vision percentage score\n",
    "\n",
    "print(f\"Overall AI Governance Vision (%): {overall_vision_pct_mean:.1f}%\")\n",
    "# Display the mean percentage score (rounded to one decimal)\n",
    "\n",
    "print(f\"Standard deviation (%): {overall_vision_pct_std:.1f}%\")\n",
    "# Display the standard deviation of the percentage score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ffcbecc-6b69-4299-9207-0248bfacd77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean Vision Score (1–4)</td>\n",
       "      <td>3.474359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Std Vision Score (1–4)</td>\n",
       "      <td>0.695314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean Vision (%)</td>\n",
       "      <td>82.478632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Std Vision (%)</td>\n",
       "      <td>23.177120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric      Value\n",
       "0  Mean Vision Score (1–4)   3.474359\n",
       "1   Std Vision Score (1–4)   0.695314\n",
       "2          Mean Vision (%)  82.478632\n",
       "3           Std Vision (%)  23.177120"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a summary table for AI governance vision\n",
    "\n",
    "# List of reported metrics included in the summary table\n",
    "vision_summary = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Mean Vision Score (1–4)\",\n",
    "        \"Std Vision Score (1–4)\",\n",
    "        \"Mean Vision (%)\",\n",
    "        \"Std Vision (%)\"\n",
    "    ],\n",
    "    # Corresponding numerical values for each metric\n",
    "    \"Value\": [\n",
    "        overall_vision_mean,\n",
    "        overall_vision_std,\n",
    "        overall_vision_pct_mean,\n",
    "        overall_vision_pct_std\n",
    "    ]\n",
    "})\n",
    "# Display the summary table\n",
    "vision_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "312b0ff8-f865-430d-b536-9b7310581a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure with a controlled aspect ratio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Vision percentage values\n",
    "vision_pct = df[\"AI_Governance_Vision_Pct\"]\n",
    "\n",
    "# Initialize the figure and axis with a compact horizontal layout\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "\n",
    "# Horizontal boxplot of AI governance vision (%)\n",
    "ax.boxplot(\n",
    "    vision_pct,\n",
    "    vert=False,\n",
    "    widths=0.4,\n",
    "    patch_artist=False\n",
    ")\n",
    "\n",
    "# Use a horizontal orientation to emphasize score distribution\n",
    "# Labels\n",
    "ax.set_xlabel(\"AI Governance Vision (%)\")\n",
    "\n",
    "# Axis limits\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Remove y-axis clutter\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Grid\n",
    "ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# ✅ SAVE AS VECTOR FORMATS\n",
    "plt.savefig(\"Results/AI_Governance_Vision_Boxplot.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "plt.savefig(\"Results/AI_Governance_Vision_Boxplot.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show (optional)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e1cd51f-8404-4eaf-a15c-f64e472e5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert new input data for prediction\n",
    "\n",
    "new_data = {\n",
    "   # Perceived benefits of using AI in governance (PBUG items)\n",
    "    \"PBUG1\": 3, \"PBUG2\": 3, \"PBUG3\": 4, \"PBUG4\": 5,\n",
    "    # Organizational understanding of AI (OUAI items)\n",
    "    \"OUAI2\": 4, \"OUAI3\": 4, \"OUAI4\": 5,\n",
    "     # Ethical–strategic thinking related to AI (EST items)\n",
    "    \"EST1\": 4, \"EST3\": 5, \"EST4\": 5\n",
    "}\n",
    "# Example input representing a new institution or decision-making unit\n",
    "\n",
    "# Convert input data to DataFrame and align feature order\n",
    "new_df = pd.DataFrame([new_data])\n",
    "# Create a single-row DataFrame from the input dictionary\n",
    "new_df = new_df[FEATURE_ORDER]\n",
    "# Reorder columns to match the feature order used during model training\n",
    "\n",
    "# Alternative: load new input data from a CSV file\n",
    "# new_df = pd.read_csv(\"new_responses.csv\")\n",
    "# Uncomment this line to load multiple new observations from an external CSV file\n",
    "\n",
    "# Generate predictions for each vision item\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "# Dictionary that will store the predicted values for each target variable\n",
    "for target, content in loaded_models.items():\n",
    "     # Iterate over each target variable and its corresponding model\n",
    "    model = content[\"model\"]\n",
    "# Retrieve the trained model for the current target\n",
    "    X_new = new_df[FEATURE_ORDER]\n",
    "    # Select the input features in the correct order\n",
    "    y_pred = model.predict(X_new)\n",
    "# Generate the prediction for the new input data\n",
    "    predictions[target] = float(y_pred[0])\n",
    "# Store the predicted value (converted to a standard Python float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8a413d3-3b4b-4252-8a84-7f7acd03f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that the input features match the expected training features\n",
    "\n",
    "expected = set(FEATURE_ORDER)\n",
    "# Set of feature names expected by the trained models (training configuration)\n",
    "\n",
    "actual = set(new_df.columns)\n",
    "# Set of feature names currently available in the new input data\n",
    "\n",
    "if expected != actual:\n",
    "    # Stop execution if the feature set is not exactly the same\n",
    "    # This prevents wrong predictions caused by missing or extra columns\n",
    "    raise ValueError(f\"Feature mismatch!\\nExpected: {expected}\\nGot: {actual}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8d629f6-52c3-4ade-bef0-467e0d3b9ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VUTAI1</th>\n",
       "      <th>VUTAI2</th>\n",
       "      <th>VUTAI3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.43954</td>\n",
       "      <td>3.773333</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VUTAI1    VUTAI2  VUTAI3\n",
       "0  4.43954  3.773333    3.73"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach predicted target values to the input DataFrame\n",
    "\n",
    "\n",
    "for k, v in predictions.items():\n",
    "    # For each predicted target variable (VUTAI1, VUTAI2, VUTAI3),\n",
    "    # add the predicted value as a new column in the DataFrame\n",
    "    new_df[k] = v\n",
    "    \n",
    "    # Display the predicted vision items (sanity check)\n",
    "\n",
    "new_df[[\"VUTAI1\", \"VUTAI2\", \"VUTAI3\"]]\n",
    "# Show predicted values for the three AI governance vision indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e0c2a0b-8789-41b6-aeb5-10229a3eb984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overall AI governance vision score and percentage from predictions\n",
    "\n",
    "new_df = compute_ai_governance_vision(\n",
    "    new_df,\n",
    "    # Use the new dataset that now includes predicted VUTAI values\n",
    "    \n",
    "    items=(\"VUTAI1\", \"VUTAI2\", \"VUTAI3\"),\n",
    "    # Compute the vision score using the predicted vision items\n",
    "    \n",
    "    score_col=\"AI_Governance_Vision\",\n",
    "    # Store the computed raw score in this column\n",
    "    \n",
    "    pct_col=\"AI_Governance_Vision_Pct\",\n",
    "    # Store the computed percentage score in this column\n",
    "    \n",
    "    scale_min=1,\n",
    "    # Minimum Likert scale value used for normalization\n",
    "    scale_max=4\n",
    "    # Maximum Likert scale value used for normalization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b473c691-68da-47b8-8a37-0a73040ec3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the percentage score into an interpretable vision level\n",
    "\n",
    "new_df[\"Vision_Level\"] = new_df[\"AI_Governance_Vision_Pct\"].apply(\n",
    "    interpret_vision_pct\n",
    ")\n",
    "# Create a qualitative label (Low / Moderate / High) based on the percentage score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06618f1a-b0a9-4eab-992d-d076a877f10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VUTAI1</th>\n",
       "      <th>VUTAI2</th>\n",
       "      <th>VUTAI3</th>\n",
       "      <th>AI_Governance_Vision</th>\n",
       "      <th>AI_Governance_Vision_Pct</th>\n",
       "      <th>Vision_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.43954</td>\n",
       "      <td>3.773333</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.980958</td>\n",
       "      <td>99.36526</td>\n",
       "      <td>High AI Governance Vision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VUTAI1    VUTAI2  VUTAI3  AI_Governance_Vision  AI_Governance_Vision_Pct  \\\n",
       "0  4.43954  3.773333    3.73              3.980958                  99.36526   \n",
       "\n",
       "                Vision_Level  \n",
       "0  High AI Governance Vision  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final output table with prediction results\n",
    "\n",
    "final_table = new_df[[\n",
    "    \"VUTAI1\", \"VUTAI2\", \"VUTAI3\",\n",
    "    # Predicted AI governance vision items\n",
    "    \"AI_Governance_Vision\",\n",
    "    # Computed overall AI governance vision score (raw scale)\n",
    "    \"AI_Governance_Vision_Pct\",\n",
    "    # Computed AI governance vision score expressed as a percentage\n",
    "    \"Vision_Level\"\n",
    "    # Qualitative interpretation of the vision score (Low / Moderate / High)\n",
    "]]\n",
    "# Display the final results table\n",
    "final_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ae28e-221f-4162-9662-924559545180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea7399-f546-471c-ba37-67cdf24797be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121d207-5173-450f-9047-21fd55286f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7fb4c-2705-4dc1-b282-4ab8736c8bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78bf0b-ec0d-4b9c-a45a-1aebb76fda5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
